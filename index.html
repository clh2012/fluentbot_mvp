<script>
  const SPEAKING_THRESHOLD = 30;  // tweak this as needed
  const SILENCE_LIMIT = 30;       // ~30 frames = 0.5 seconds at 60fps

  let mediaRecorder;
  let audioChunks = [];
  let analyser, dataArray, silenceTimer = 0;
  let stream, audioContext, source;

  async function setupMicrophone() {
    stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    audioContext = new AudioContext();
    source = audioContext.createMediaStreamSource(stream);
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    source.connect(analyser);
    startListeningLoop();
  }

  function startListeningLoop() {
    detectSpeech();
  }

  function detectSpeech() {
    analyser.getByteFrequencyData(dataArray);
    const avgVolume = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

    if (avgVolume > SPEAKING_THRESHOLD) {
      if (!mediaRecorder || mediaRecorder.state === 'inactive') {
        startRecording();
      }
      silenceTimer = 0;
    } else {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        silenceTimer++;
        if (silenceTimer > SILENCE_LIMIT) {
          stopRecording();
        }
      }
    }

    requestAnimationFrame(detectSpeech);
  }

  function startRecording() {
    console.log("🎙️ Recording started");
    audioChunks = [];
    mediaRecorder = new MediaRecorder(stream);
    mediaRecorder.ondataavailable = (event) => audioChunks.push(event.data);
    mediaRecorder.onstop = handleRecordingStop;
    mediaRecorder.start();
  }

  function stopRecording() {
    console.log("🛑 Recording stopped");
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
    }
  }

  async function handleRecordingStop() {
    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    const formData = new FormData();
    formData.append('audio', audioBlob, 'input.webm');

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        body: formData
      });

      const audioBuffer = await response.arrayBuffer();
      const audioCtx = new AudioContext();
      const decoded = await audioCtx.decodeAudioData(audioBuffer);
      const source = audioCtx.createBufferSource();
      source.buffer = decoded;
      source.connect(audioCtx.destination);
      source.start();

      source.onended = () => {
        console.log("🔁 Ready for next input...");
        startListeningLoop(); // continue the loop
      };
    } catch (err) {
      console.error('Error handling audio:', err);
    }
  }

  // Start everything
  setupMicrophone();
</script>
