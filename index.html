<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Fluent Hero â€“ Audio Practice</title>
  <style>
    body {
      font-family: sans-serif;
      max-width: 600px;
      margin: 2em auto;
      padding: 1em;
      background: #f9f9f9;
      color: #333;
      line-height: 1.6;
    }
    button {
      padding: 0.5em 1em;
      font-size: 1rem;
      border: none;
      background: #007bff;
      color: white;
      border-radius: 5px;
      cursor: pointer;
    }
    button:hover {
      background: #0056b3;
    }
    textarea {
      font-family: inherit;
      font-size: 1rem;
      padding: 0.5em;
      border-radius: 5px;
      border: 1px solid #ccc;
      resize: vertical;
    }
    audio {
      width: 100%;
    }
    #chatContainer {
      background: white;
      border: 1px solid #ccc;
      border-radius: 5px;
      padding: 1em;
      margin-top: 2em;
      max-height: 300px;
      overflow-y: auto;
    }
    .bubble {
      margin: 0.5em 0;
      padding: 0.6em 1em;
      border-radius: 15px;
      max-width: 80%;
      line-height: 1.4;
      word-wrap: break-word;
    }
    .user {
      background: #007bff;
      color: white;
      margin-left: auto;
      text-align: right;
      border-bottom-right-radius: 0;
    }
    .assistant {
      background: #e5e5ea;
      color: #333;
      margin-right: auto;
      text-align: left;
      border-bottom-left-radius: 0;
    }
  </style>
</head>
<body>

  <h1>ðŸŽ§ Fluent Hero â€“ Audio Practice</h1>

  <div style="margin-top: 1em;">
    <button id="recordBtn">ðŸŽ¤ Start Recording</button>
    <p id="recordingStatus"></p>
    <progress id="audioLevel" value="0" max="1" style="width: 100%; display: none; margin-top: 0.5em;"></progress>

    <audio id="audioPlayback" controls style="display:none; margin-top:1em;"></audio>

    <textarea id="transcript" rows="5" style="width: 100%; margin-top:1em;" placeholder="Transcription will appear here..."></textarea>

    <button id="speakBtn" style="margin-top: 0.5em;">ðŸ”ˆ Speak Text</button>

    <audio id="ttsAudio" controls style="display:none; margin-top:1em;"></audio>
  </div>

  <!-- Chat container added -->
  <div id="chatContainer"></div>

  <script>
    const API_BASE = 'https://fluentbot-mvp-am46.vercel.app/';

    let mediaRecorder;
    let audioChunks = [];
    let audioContext;
    let analyser;
    let animationId;

    const recordBtn = document.getElementById("recordBtn");
    const status = document.getElementById("recordingStatus");
    const audioPlayback = document.getElementById("audioPlayback");
    const audioLevel = document.getElementById("audioLevel");
    const transcriptEl = document.getElementById("transcript");
    const speakBtn = document.getElementById("speakBtn");
    const ttsAudio = document.getElementById("ttsAudio");
    const chatContainer = document.getElementById("chatContainer");

    recordBtn.addEventListener("click", async () => {
      if (!mediaRecorder || mediaRecorder.state === "inactive") {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          audioChunks = [];

          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

          audioContext = new AudioContext();
          const source = audioContext.createMediaStreamSource(stream);
          analyser = audioContext.createAnalyser();
          source.connect(analyser);
          const bufferLength = analyser.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);

          function draw() {
            analyser.getByteFrequencyData(dataArray);
            const volume = dataArray.reduce((a, b) => a + b, 0) / bufferLength;
            audioLevel.value = volume / 100;
            animationId = requestAnimationFrame(draw);
          }

          draw();
          audioLevel.style.display = "block";
          status.textContent = "Recording...";
          mediaRecorder.start();
          recordBtn.textContent = "â¹ï¸ Stop Recording";

          mediaRecorder.onstop = async () => {
            cancelAnimationFrame(animationId);
            audioLevel.style.display = "none";
            await audioContext.close();

            const blob = new Blob(audioChunks, { type: "audio/webm" });
            const audioURL = URL.createObjectURL(blob);
            audioPlayback.src = audioURL;
            audioPlayback.style.display = "block";
            status.textContent = "Transcribing...";

            const formData = new FormData();
            formData.append('audio', blob, 'recording.webm');

            try {
              const response = await fetch(`${API_BASE}/api/transcribe`, {
                method: 'POST',
                body: formData,
              });

              if (!response.ok) throw new Error("Transcription failed");
              const data = await response.json();

              if (data.transcript) {
                transcriptEl.value = data.transcript;
                status.textContent = "Transcription complete.";
                await send
